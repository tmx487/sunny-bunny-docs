Вот несколько подходов для параллельного чтения больших CSV файлов по частям в C#:Я показал 4 различных подхода для параллельного чтения больших CSV файлов:

**1. Подход с батчами (CsvParallelReader)**

- Загружает весь файл в память
- Разделяет на батчи по количеству строк
- Обрабатывает каждый батч в отдельном потоке
- Подходит для файлов до 100-200MB

**2. Разделение по байтам (CsvStreamParallelReader)**

- Разделяет файл на части по размеру в байтах
- Каждый поток читает свою часть файла
- Более эффективен для очень больших файлов (1M+ строк)
- Не загружает весь файл в память

**3. Производитель-потребитель с каналами (CsvChannelReader)**

- Один поток читает файл и отправляет батчи в канал
- Несколько потоков обрабатывают батчи параллельно
- Хорошо для потоковой обработки
- Низкое потребление памяти

**4. Partitioner (CsvPartitionReader)**

- Использует встроенный Partitioner для автоматического разделения работы
- Самый простой в использовании
- Оптимален для CPU-intensive операций

**Рекомендации:**

- Для файлов 300K-500K строк: используйте подход 1 или 4
- Для файлов 500K-1M строк: используйте подход 2 или 3
- Для более сложного парсинга CSV (с кавычками, экранированием): используйте библиотеку CsvHelper или доработайте CsvParser

```csharp
using System;
using System.Collections.Concurrent;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System.Threading.Tasks;

// Подход 1: Разделение по количеству строк
public class CsvParallelReader
{
    public static async Task<List<string[]>> ReadCsvInParallel(string filePath, int batchSize = 10000)
    {
        var allLines = await File.ReadAllLinesAsync(filePath);
        var result = new ConcurrentBag<string[]>();
        
        // Разбиваем на батчи
        var batches = allLines
            .Select((line, index) => new { Line = line, Index = index })
            .GroupBy(x => x.Index / batchSize)
            .Select(g => g.Select(x => x.Line).ToArray())
            .ToList();

        // Обрабатываем батчи параллельно
        await Task.Run(() =>
        {
            Parallel.ForEach(batches, batch =>
            {
                var processedBatch = ProcessBatch(batch);
                foreach (var row in processedBatch)
                {
                    result.Add(row);
                }
            });
        });

        return result.ToList();
    }

    private static List<string[]> ProcessBatch(string[] lines)
    {
        var result = new List<string[]>();
        foreach (var line in lines)
        {
            // Простой парсинг CSV (для более сложных случаев используйте CsvHelper)
            var fields = line.Split(',');
            result.Add(fields);
        }
        return result;
    }
}

// Подход 2: Разделение файла по байтам для больших файлов
public class CsvStreamParallelReader
{
    public static async Task<ConcurrentBag<string[]>> ReadLargeeCsvInParallel(
        string filePath, 
        int numberOfThreads = Environment.ProcessorCount)
    {
        var fileInfo = new FileInfo(filePath);
        var fileSize = fileInfo.Length;
        var chunkSize = fileSize / numberOfThreads;
        
        var result = new ConcurrentBag<string[]>();
        var tasks = new List<Task>();

        for (int i = 0; i < numberOfThreads; i++)
        {
            var threadIndex = i;
            var task = Task.Run(async () =>
            {
                var startPosition = threadIndex * chunkSize;
                var endPosition = (threadIndex == numberOfThreads - 1) 
                    ? fileSize 
                    : (threadIndex + 1) * chunkSize;

                await ReadChunk(filePath, startPosition, endPosition, result, threadIndex);
            });
            
            tasks.Add(task);
        }

        await Task.WhenAll(tasks);
        return result;
    }

    private static async Task ReadChunk(
        string filePath, 
        long startPosition, 
        long endPosition, 
        ConcurrentBag<string[]> result,
        int threadIndex)
    {
        using var fileStream = new FileStream(filePath, FileMode.Open, FileAccess.Read, FileShare.Read);
        using var reader = new StreamReader(fileStream);
        
        // Переходим к начальной позиции
        fileStream.Seek(startPosition, SeekOrigin.Begin);
        
        // Если не первый поток, пропускаем неполную строку
        if (startPosition > 0)
        {
            await reader.ReadLineAsync();
        }

        string line;
        while ((line = await reader.ReadLineAsync()) != null && 
               fileStream.Position < endPosition)
        {
            var fields = ParseCsvLine(line);
            result.Add(fields);
        }
    }

    private static string[] ParseCsvLine(string line)
    {
        // Простой парсинг - для продакшена используйте более надежный парсер
        return line.Split(',');
    }
}

// Подход 3: Производитель-потребитель с каналами
public class CsvChannelReader
{
    public static async Task ReadCsvWithChannels(string filePath, int batchSize = 5000)
    {
        var channel = System.Threading.Channels.Channel.CreateUnbounded<string[]>();
        var writer = channel.Writer;
        var reader = channel.Reader;

        // Производитель - читает файл и отправляет батчи в канал
        var producerTask = Task.Run(async () =>
        {
            try
            {
                using var fileReader = new StreamReader(filePath);
                var batch = new List<string>();
                string line;

                while ((line = await fileReader.ReadLineAsync()) != null)
                {
                    batch.Add(line);
                    
                    if (batch.Count >= batchSize)
                    {
                        await writer.WriteAsync(batch.ToArray());
                        batch.Clear();
                    }
                }

                // Отправляем последний батч
                if (batch.Count > 0)
                {
                    await writer.WriteAsync(batch.ToArray());
                }
            }
            finally
            {
                writer.Complete();
            }
        });

        // Потребители - обрабатывают батчи параллельно
        var consumerTasks = new List<Task>();
        for (int i = 0; i < Environment.ProcessorCount; i++)
        {
            var consumerTask = Task.Run(async () =>
            {
                await foreach (var batch in reader.ReadAllAsync())
                {
                    ProcessBatchAsync(batch);
                }
            });
            consumerTasks.Add(consumerTask);
        }

        await Task.WhenAll(producerTask);
        await Task.WhenAll(consumerTasks);
    }

    private static void ProcessBatchAsync(string[] batch)
    {
        // Обработка батча
        foreach (var line in batch)
        {
            var fields = line.Split(',');
            // Ваша логика обработки
            Console.WriteLine($"Thread {System.Threading.Thread.CurrentThread.ManagedThreadId}: {fields.Length} fields");
        }
    }
}

// Подход 4: Использование Parallel.ForEach с Partitioner
public class CsvPartitionReader
{
    public static async Task ReadCsvWithPartitioner(string filePath, int batchSize = 10000)
    {
        var lines = await File.ReadAllLinesAsync(filePath);
        var partitioner = Partitioner.Create(lines, true);
        var result = new ConcurrentBag<string[]>();

        Parallel.ForEach(partitioner, line =>
        {
            var fields = line.Split(',');
            result.Add(fields);
        });

        Console.WriteLine($"Processed {result.Count} lines");
    }
}

// Пример использования
public class Program
{
    public static async Task Main(string[] args)
    {
        string csvFilePath = "large_file.csv";
        
        Console.WriteLine("Метод 1: Чтение батчами");
        var result1 = await CsvParallelReader.ReadCsvInParallel(csvFilePath, 10000);
        Console.WriteLine($"Обработано строк: {result1.Count}");

        Console.WriteLine("\nМетод 2: Разделение по байтам");
        var result2 = await CsvStreamParallelReader.ReadLargeeCsvInParallel(csvFilePath, 4);
        Console.WriteLine($"Обработано строк: {result2.Count}");

        Console.WriteLine("\nМетод 3: Каналы");
        await CsvChannelReader.ReadCsvWithChannels(csvFilePath, 5000);

        Console.WriteLine("\nМетод 4: Partitioner");
        await CsvPartitionReader.ReadCsvWithPartitioner(csvFilePath, 10000);
    }
}

// Дополнительный класс для более сложного парсинга CSV
public static class CsvParser
{
    public static string[] ParseCsvLine(string line)
    {
        var result = new List<string>();
        var current = new System.Text.StringBuilder();
        bool inQuotes = false;
        
        for (int i = 0; i < line.Length; i++)
        {
            char c = line[i];
            
            if (c == '"')
            {
                inQuotes = !inQuotes;
            }
            else if (c == ',' && !inQuotes)
            {
                result.Add(current.ToString());
                current.Clear();
            }
            else
            {
                current.Append(c);
            }
        }
        
        result.Add(current.ToString());
        return result.ToArray();
    }
}
```


# way #2

```csharp
using System;
using System.Collections.Concurrent;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System.Threading.Tasks;

public class ParallelCsvReader
{
    public class CsvRow
    {
        public int LineNumber { get; set; }
        public string[] Fields { get; set; }
    }

    public async Task<List<CsvRow>> ReadCsvAsync(string filePath, int threadCount, char delimiter = ',')
    {
        if (!File.Exists(filePath))
            throw new FileNotFoundException($"Файл {filePath} не найден");

        if (threadCount <= 0)
            throw new ArgumentException("Количество потоков должно быть больше 0");

        var fileInfo = new FileInfo(filePath);
        var fileSize = fileInfo.Length;

        // Читаем весь файл в массив строк для точного разделения
        var allLines = await File.ReadAllLinesAsync(filePath);
        var totalLines = allLines.Length;

        if (totalLines == 0)
            return new List<CsvRow>();

        // Разделяем строки между потоками
        var linesPerThread = totalLines / threadCount;
        var remainder = totalLines % threadCount;

        var result = new ConcurrentBag<CsvRow>();
        var tasks = new List<Task>();

        int startIndex = 0;
        for (int i = 0; i < threadCount; i++)
        {
            int currentThreadLines = linesPerThread + (i < remainder ? 1 : 0);
            int endIndex = startIndex + currentThreadLines;

            var threadStartIndex = startIndex;
            var threadEndIndex = Math.Min(endIndex, totalLines);

            tasks.Add(Task.Run(() =>
            {
                ProcessLines(allLines, threadStartIndex, threadEndIndex, delimiter, result);
            }));

            startIndex = endIndex;
        }

        await Task.WhenAll(tasks);

        // Сортируем результат по номеру строки
        return result.OrderBy(r => r.LineNumber).ToList();
    }

    private void ProcessLines(string[] lines, int startIndex, int endIndex, char delimiter, ConcurrentBag<CsvRow> result)
    {
        for (int i = startIndex; i < endIndex; i++)
        {
            var line = lines[i];
            
            // Пропускаем пустые строки
            if (string.IsNullOrWhiteSpace(line))
                continue;

            var fields = ParseCsvLine(line, delimiter);
            
            result.Add(new CsvRow
            {
                LineNumber = i + 1, // Нумерация с 1
                Fields = fields
            });
        }
    }

    private string[] ParseCsvLine(string line, char delimiter)
    {
        var fields = new List<string>();
        var currentField = "";
        bool inQuotes = false;
        bool nextCharIsEscaped = false;

        for (int i = 0; i < line.Length; i++)
        {
            char c = line[i];

            if (nextCharIsEscaped)
            {
                currentField += c;
                nextCharIsEscaped = false;
                continue;
            }

            if (c == '"' && !inQuotes)
            {
                inQuotes = true;
            }
            else if (c == '"' && inQuotes)
            {
                // Проверяем следующий символ для экранирования
                if (i + 1 < line.Length && line[i + 1] == '"')
                {
                    currentField += '"';
                    nextCharIsEscaped = true;
                }
                else
                {
                    inQuotes = false;
                }
            }
            else if (c == delimiter && !inQuotes)
            {
                fields.Add(currentField);
                currentField = "";
            }
            else
            {
                currentField += c;
            }
        }

        fields.Add(currentField);
        return fields.ToArray();
    }

    // Альтернативный метод для очень больших файлов (стриминг)
    public async Task<List<CsvRow>> ReadCsvStreamAsync(string filePath, int threadCount, char delimiter = ',')
    {
        if (!File.Exists(filePath))
            throw new FileNotFoundException($"Файл {filePath} не найден");

        var fileInfo = new FileInfo(filePath);
        var fileSize = fileInfo.Length;
        var segmentSize = fileSize / threadCount;

        var result = new ConcurrentBag<CsvRow>();
        var tasks = new List<Task>();

        for (int i = 0; i < threadCount; i++)
        {
            var startPosition = i * segmentSize;
            var endPosition = (i == threadCount - 1) ? fileSize : (i + 1) * segmentSize;

            tasks.Add(Task.Run(async () =>
            {
                await ProcessFileSegmentAsync(filePath, startPosition, endPosition, delimiter, result, i);
            }));
        }

        await Task.WhenAll(tasks);

        return result.OrderBy(r => r.LineNumber).ToList();
    }

    private async Task ProcessFileSegmentAsync(string filePath, long startPosition, long endPosition, 
        char delimiter, ConcurrentBag<CsvRow> result, int threadIndex)
    {
        using var fileStream = new FileStream(filePath, FileMode.Open, FileAccess.Read, FileShare.Read);
        using var reader = new StreamReader(fileStream);

        fileStream.Seek(startPosition, SeekOrigin.Begin);

        // Если не первый поток, пропускаем до начала следующей строки
        if (startPosition > 0)
        {
            await reader.ReadLineAsync();
        }

        int lineNumber = 0;
        string line;
        
        while ((line = await reader.ReadLineAsync()) != null)
        {
            if (fileStream.Position > endPosition && threadIndex < threadCount - 1)
                break;

            if (string.IsNullOrWhiteSpace(line))
                continue;

            var fields = ParseCsvLine(line, delimiter);
            
            result.Add(new CsvRow
            {
                LineNumber = (int)(startPosition + lineNumber),
                Fields = fields
            });

            lineNumber++;
        }
    }
}

// Пример использования
public class Program
{
    public static async Task Main(string[] args)
    {
        var reader = new ParallelCsvReader();
        
        try
        {
            // Чтение с 4 потоками
            var results = await reader.ReadCsvAsync("large_file.csv", 4);
            
            Console.WriteLine($"Прочитано {results.Count} строк");
            
            // Выводим первые 10 строк
            foreach (var row in results.Take(10))
            {
                Console.WriteLine($"Строка {row.LineNumber}: {string.Join(" | ", row.Fields)}");
            }
        }
        catch (Exception ex)
        {
            Console.WriteLine($"Ошибка: {ex.Message}");
        }
    }
}
```

# Generic Mapping from CSV to custom types

```csharp
using System;
using System.Collections.Concurrent;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System.Reflection;
using System.Threading.Tasks;
using System.ComponentModel;

// Атрибут для настройки маппинга
[AttributeUsage(AttributeTargets.Property | AttributeTargets.Field)]
public class CsvColumnAttribute : Attribute
{
    public string Name { get; }
    public int Index { get; }
    
    public CsvColumnAttribute(string name)
    {
        Name = name;
        Index = -1;
    }
    
    public CsvColumnAttribute(int index)
    {
        Index = index;
        Name = null;
    }
}

public class ParallelCsvReader
{
    public class CsvRow<T>
    {
        public int LineNumber { get; set; }
        public T Data { get; set; }
        public bool IsValid { get; set; }
        public string Error { get; set; }
    }

    // Generic метод для чтения в пользовательский тип
    public async Task<List<CsvRow<T>>> ReadCsvAsync<T>(string filePath, int threadCount, 
        char delimiter = ',', bool hasHeader = true) where T : new()
    {
        if (!File.Exists(filePath))
            throw new FileNotFoundException($"Файл {filePath} не найден");

        var allLines = await File.ReadAllLinesAsync(filePath);
        if (allLines.Length == 0)
            return new List<CsvRow<T>>();

        string[] headers = null;
        int dataStartIndex = 0;

        if (hasHeader)
        {
            headers = ParseCsvLine(allLines[0], delimiter);
            dataStartIndex = 1;
        }

        var mapper = new CsvMapper<T>(headers);
        var dataLines = allLines.Skip(dataStartIndex).ToArray();
        var totalLines = dataLines.Length;

        if (totalLines == 0)
            return new List<CsvRow<T>>();

        var linesPerThread = totalLines / threadCount;
        var remainder = totalLines % threadCount;

        var result = new ConcurrentBag<CsvRow<T>>();
        var tasks = new List<Task>();

        int startIndex = 0;
        for (int i = 0; i < threadCount; i++)
        {
            int currentThreadLines = linesPerThread + (i < remainder ? 1 : 0);
            int endIndex = startIndex + currentThreadLines;

            var threadStartIndex = startIndex;
            var threadEndIndex = Math.Min(endIndex, totalLines);

            tasks.Add(Task.Run(() =>
            {
                ProcessLines(dataLines, threadStartIndex, threadEndIndex, delimiter, 
                    mapper, result, dataStartIndex);
            }));

            startIndex = endIndex;
        }

        await Task.WhenAll(tasks);

        return result.OrderBy(r => r.LineNumber).ToList();
    }

    private void ProcessLines<T>(string[] lines, int startIndex, int endIndex, char delimiter,
        CsvMapper<T> mapper, ConcurrentBag<CsvRow<T>> result, int lineNumberOffset) where T : new()
    {
        for (int i = startIndex; i < endIndex; i++)
        {
            var line = lines[i];
            
            if (string.IsNullOrWhiteSpace(line))
                continue;

            var fields = ParseCsvLine(line, delimiter);
            var csvRow = new CsvRow<T>
            {
                LineNumber = i + lineNumberOffset + 1
            };

            try
            {
                csvRow.Data = mapper.MapToObject(fields);
                csvRow.IsValid = true;
            }
            catch (Exception ex)
            {
                csvRow.IsValid = false;
                csvRow.Error = ex.Message;
                csvRow.Data = default(T);
            }

            result.Add(csvRow);
        }
    }

    private string[] ParseCsvLine(string line, char delimiter)
    {
        var fields = new List<string>();
        var currentField = "";
        bool inQuotes = false;
        bool nextCharIsEscaped = false;

        for (int i = 0; i < line.Length; i++)
        {
            char c = line[i];

            if (nextCharIsEscaped)
            {
                currentField += c;
                nextCharIsEscaped = false;
                continue;
            }

            if (c == '"' && !inQuotes)
            {
                inQuotes = true;
            }
            else if (c == '"' && inQuotes)
            {
                if (i + 1 < line.Length && line[i + 1] == '"')
                {
                    currentField += '"';
                    nextCharIsEscaped = true;
                }
                else
                {
                    inQuotes = false;
                }
            }
            else if (c == delimiter && !inQuotes)
            {
                fields.Add(currentField);
                currentField = "";
            }
            else
            {
                currentField += c;
            }
        }

        fields.Add(currentField);
        return fields.ToArray();
    }
}

// Класс для маппинга CSV строк в объекты
public class CsvMapper<T> where T : new()
{
    private readonly Dictionary<int, PropertyInfo> _propertyMap = new();
    private readonly Dictionary<int, FieldInfo> _fieldMap = new();

    public CsvMapper(string[] headers)
    {
        BuildMapping(headers);
    }

    private void BuildMapping(string[] headers)
    {
        var type = typeof(T);
        
        // Маппинг свойств
        var properties = type.GetProperties(BindingFlags.Public | BindingFlags.Instance)
            .Where(p => p.CanWrite);

        foreach (var prop in properties)
        {
            var csvAttr = prop.GetCustomAttribute<CsvColumnAttribute>();
            
            if (csvAttr != null)
            {
                // Используем атрибут для маппинга
                if (csvAttr.Index >= 0)
                {
                    _propertyMap[csvAttr.Index] = prop;
                }
                else if (headers != null && !string.IsNullOrEmpty(csvAttr.Name))
                {
                    var index = Array.FindIndex(headers, h => 
                        string.Equals(h.Trim(), csvAttr.Name, StringComparison.OrdinalIgnoreCase));
                    if (index >= 0)
                        _propertyMap[index] = prop;
                }
            }
            else if (headers != null)
            {
                // Автоматический маппинг по имени свойства
                var index = Array.FindIndex(headers, h => 
                    string.Equals(h.Trim(), prop.Name, StringComparison.OrdinalIgnoreCase));
                if (index >= 0)
                    _propertyMap[index] = prop;
            }
        }

        // Маппинг полей (для records)
        var fields = type.GetFields(BindingFlags.Public | BindingFlags.Instance);
        foreach (var field in fields)
        {
            var csvAttr = field.GetCustomAttribute<CsvColumnAttribute>();
            
            if (csvAttr != null)
            {
                if (csvAttr.Index >= 0)
                {
                    _fieldMap[csvAttr.Index] = field;
                }
                else if (headers != null && !string.IsNullOrEmpty(csvAttr.Name))
                {
                    var index = Array.FindIndex(headers, h => 
                        string.Equals(h.Trim(), csvAttr.Name, StringComparison.OrdinalIgnoreCase));
                    if (index >= 0)
                        _fieldMap[index] = field;
                }
            }
            else if (headers != null)
            {
                var index = Array.FindIndex(headers, h => 
                    string.Equals(h.Trim(), field.Name, StringComparison.OrdinalIgnoreCase));
                if (index >= 0)
                    _fieldMap[index] = field;
            }
        }
    }

    public T MapToObject(string[] csvFields)
    {
        var obj = new T();

        // Заполняем свойства
        foreach (var kvp in _propertyMap)
        {
            var index = kvp.Key;
            var property = kvp.Value;

            if (index < csvFields.Length)
            {
                var value = ConvertValue(csvFields[index], property.PropertyType);
                property.SetValue(obj, value);
            }
        }

        // Заполняем поля
        foreach (var kvp in _fieldMap)
        {
            var index = kvp.Key;
            var field = kvp.Value;

            if (index < csvFields.Length)
            {
                var value = ConvertValue(csvFields[index], field.FieldType);
                field.SetValue(obj, value);
            }
        }

        return obj;
    }

    private object ConvertValue(string value, Type targetType)
    {
        if (string.IsNullOrWhiteSpace(value))
        {
            if (targetType.IsValueType && Nullable.GetUnderlyingType(targetType) == null)
                return Activator.CreateInstance(targetType);
            return null;
        }

        // Обработка Nullable типов
        var underlyingType = Nullable.GetUnderlyingType(targetType);
        if (underlyingType != null)
            targetType = underlyingType;

        // Используем TypeConverter для преобразования
        var converter = TypeDescriptor.GetConverter(targetType);
        if (converter.CanConvertFrom(typeof(string)))
        {
            return converter.ConvertFromString(value.Trim());
        }

        // Fallback на Convert.ChangeType
        return Convert.ChangeType(value.Trim(), targetType);
    }
}

// Примеры использования
public record Person(string Name, int Age, string Email);

public class Employee
{
    [CsvColumn("Full Name")]
    public string Name { get; set; }
    
    [CsvColumn(1)] // По индексу
    public int Age { get; set; }
    
    public string Department { get; set; }
    
    [CsvColumn("Salary")]
    public decimal? Salary { get; set; }
}

public class Program
{
    public static async Task Main(string[] args)
    {
        var reader = new ParallelCsvReader();

        try
        {
            // Пример 1: Простой record
            var people = await reader.ReadCsvAsync<Person>("people.csv", 4);
            
            Console.WriteLine("=== Люди ===");
            foreach (var row in people.Where(r => r.IsValid).Take(5))
            {
                Console.WriteLine($"Строка {row.LineNumber}: {row.Data.Name}, {row.Data.Age} лет, {row.Data.Email}");
            }

            // Пример 2: Класс с атрибутами
            var employees = await reader.ReadCsvAsync<Employee>("employees.csv", 4);
            
            Console.WriteLine("\n=== Сотрудники ===");
            foreach (var row in employees.Where(r => r.IsValid).Take(5))
            {
                var emp = row.Data;
                Console.WriteLine($"Строка {row.LineNumber}: {emp.Name}, {emp.Age} лет, {emp.Department}, {emp.Salary:C}");
            }

            // Показываем ошибки
            var errors = employees.Where(r => !r.IsValid).Take(3);
            Console.WriteLine("\n=== Ошибки ===");
            foreach (var error in errors)
            {
                Console.WriteLine($"Строка {error.LineNumber}: {error.Error}");
            }
        }
        catch (Exception ex)
        {
            Console.WriteLine($"Ошибка: {ex.Message}");
        }
    }
}
```

# way 3

```csharp
using System;
using System.Collections.Generic;
using System.IO;
using System.Globalization;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.Extensions.Logging;

public class OptimizedCsvReader
{
    private readonly ILogger<OptimizedCsvReader> _logger;
    private const int BATCH_SIZE = 1000;

    public OptimizedCsvReader(ILogger<OptimizedCsvReader> logger)
    {
        _logger = logger;
    }

    // Вариант 1: Потоковое чтение (рекомендуется для больших файлов)
    public async Task<IEnumerable<ReadFileResponse>> ReadByBatchStreaming(
        string filePath,
        int page,
        int pageSize,
        CancellationToken cancellationToken)
    {
        _logger.LogInformation("Reading csv file started...");
        
        if (!File.Exists(filePath))
        {
            _logger.LogError("File {FilePath} not found", filePath);
            return Enumerable.Empty<ReadFileResponse>();
        }

        var result = new List<ReadFileResponse>();
        var skipCount = (page - 1) * pageSize;
        var currentIndex = 0;
        var processedCount = 0;

        using var fileStream = new FileStream(filePath, FileMode.Open, FileAccess.Read, FileShare.Read);
        using var reader = new StreamReader(fileStream);

        // Пропускаем заголовок
        await reader.ReadLineAsync();

        string line;
        while ((line = await reader.ReadLineAsync()) != null && 
               processedCount < pageSize && 
               !cancellationToken.IsCancellationRequested)
        {
            // Пропускаем строки до нужной страницы
            if (currentIndex < skipCount)
            {
                currentIndex++;
                continue;
            }

            var response = ProcessLine(line, currentIndex + 1);
            if (response != null)
            {
                result.Add(response);
                processedCount++;
            }

            currentIndex++;
        }

        _logger.LogInformation("Processed {Count} rows for page {Page}", processedCount, page);
        return result;
    }

    // Вариант 2: Параллельное чтение всего файла (если нужна полная обработка)
    public async Task<IEnumerable<ReadFileResponse>> ReadByBatchParallel(
        string filePath,
        int page,
        int pageSize,
        CancellationToken cancellationToken)
    {
        _logger.LogInformation("Reading csv file started...");
        
        if (!File.Exists(filePath))
        {
            _logger.LogError("File {FilePath} not found", filePath);
            return Enumerable.Empty<ReadFileResponse>();
        }

        var allLines = await File.ReadAllLinesAsync(filePath, cancellationToken);
        var dataLines = allLines.Skip(1).ToArray(); // Пропускаем заголовок

        var result = new List<ReadFileResponse>();
        var skipCount = (page - 1) * pageSize;
        var takeCount = Math.Min(pageSize, dataLines.Length - skipCount);

        if (skipCount >= dataLines.Length)
        {
            return result;
        }

        // Обрабатываем только нужные строки
        var linesToProcess = dataLines.Skip(skipCount).Take(takeCount).ToArray();
        
        // Разбиваем на батчи для параллельной обработки
        var batches = CreateBatches(linesToProcess, BATCH_SIZE);
        var tasks = new List<Task<List<ReadFileResponse>>>();

        foreach (var batch in batches)
        {
            tasks.Add(Task.Run(() => ProcessBatch(batch, cancellationToken), cancellationToken));
        }

        var batchResults = await Task.WhenAll(tasks);
        
        // Объединяем результаты с сохранением порядка
        foreach (var batchResult in batchResults)
        {
            result.AddRange(batchResult);
        }

        _logger.LogInformation("Processed {Count} rows for page {Page}", result.Count, page);
        return result;
    }

    // Вариант 3: Асинхронное потоковое чтение с батчами
    public async Task<IEnumerable<ReadFileResponse>> ReadByBatchAsync(
        string filePath,
        int page,
        int pageSize,
        CancellationToken cancellationToken)
    {
        _logger.LogInformation("Reading csv file started...");
        
        if (!File.Exists(filePath))
        {
            _logger.LogError("File {FilePath} not found", filePath);
            return Enumerable.Empty<ReadFileResponse>();
        }

        var skipCount = (page - 1) * pageSize;
        var result = new List<ReadFileResponse>();

        await foreach (var batch in ReadBatchesAsync(filePath, skipCount, pageSize, cancellationToken))
        {
            var processedBatch = ProcessBatch(batch, cancellationToken);
            result.AddRange(processedBatch);
        }

        return result;
    }

    private async IAsyncEnumerable<string[]> ReadBatchesAsync(
        string filePath, 
        int skipCount, 
        int takeCount, 
        CancellationToken cancellationToken)
    {
        using var fileStream = new FileStream(filePath, FileMode.Open, FileAccess.Read, FileShare.Read);
        using var reader = new StreamReader(fileStream);

        // Пропускаем заголовок
        await reader.ReadLineAsync();

        var currentIndex = 0;
        var processedCount = 0;
        var batch = new List<string>();

        string line;
        while ((line = await reader.ReadLineAsync()) != null && 
               processedCount < takeCount && 
               !cancellationToken.IsCancellationRequested)
        {
            // Пропускаем строки до нужной страницы
            if (currentIndex < skipCount)
            {
                currentIndex++;
                continue;
            }

            batch.Add(line);
            processedCount++;

            // Возвращаем батч когда он заполнен
            if (batch.Count >= BATCH_SIZE)
            {
                yield return batch.ToArray();
                batch.Clear();
            }

            currentIndex++;
        }

        // Возвращаем последний неполный батч
        if (batch.Count > 0)
        {
            yield return batch.ToArray();
        }
    }

    private List<ReadFileResponse> ProcessBatch(string[] batch, CancellationToken cancellationToken)
    {
        var result = new List<ReadFileResponse>();
        
        foreach (var line in batch)
        {
            if (cancellationToken.IsCancellationRequested)
                break;

            var response = ProcessLine(line, 0); // Номер строки можно передать отдельно
            if (response != null)
            {
                result.Add(response);
            }
        }

        return result;
    }

    private ReadFileResponse ProcessLine(string line, int lineNumber)
    {
        try
        {
            var fields = ParseCsvLine(line);
            
            if (fields.Length < 7)
            {
                _logger.LogWarning("Line {LineNumber}: Invalid field count. Expected 7, got {Count}", 
                    lineNumber, fields.Length);
                return null;
            }

            if (!decimal.TryParse(fields[5], NumberStyles.Number, CultureInfo.InvariantCulture, out decimal amount))
            {
                _logger.LogWarning("Line {LineNumber}: Invalid amount value '{Amount}'", 
                    lineNumber, fields[5]);
                return null;
            }

            return new ReadFileResponse(
                fields[0]?.Trim(),
                amount,
                fields[6]?.Trim());
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Error processing line {LineNumber}: {Line}", lineNumber, line);
            return null;
        }
    }

    private string[] ParseCsvLine(string line)
    {
        // Упрощённый парсер CSV (для production лучше использовать библиотеку)
        var fields = new List<string>();
        var currentField = "";
        bool inQuotes = false;

        for (int i = 0; i < line.Length; i++)
        {
            char c = line[i];

            if (c == '"')
            {
                inQuotes = !inQuotes;
            }
            else if (c == ',' && !inQuotes)
            {
                fields.Add(currentField);
                currentField = "";
            }
            else
            {
                currentField += c;
            }
        }

        fields.Add(currentField);
        return fields.ToArray();
    }

    private static IEnumerable<T[]> CreateBatches<T>(IEnumerable<T> source, int batchSize)
    {
        var batch = new List<T>(batchSize);
        foreach (var item in source)
        {
            batch.Add(item);
            if (batch.Count == batchSize)
            {
                yield return batch.ToArray();
                batch.Clear();
            }
        }
        
        if (batch.Count > 0)
        {
            yield return batch.ToArray();
        }
    }

    private bool IsFileExists(string filePath) => File.Exists(filePath);
}

public record ReadFileResponse(string Field1, decimal Amount, string Field7);

// Пример использования
public class CsvService
{
    private readonly OptimizedCsvReader _reader;

    public CsvService(OptimizedCsvReader reader)
    {
        _reader = reader;
    }

    public async Task<IEnumerable<ReadFileResponse>> GetPage(string filePath, int page, int pageSize)
    {
        using var cts = new CancellationTokenSource();
        
        // Для больших файлов используйте потоковое чтение
        return await _reader.ReadByBatchStreaming(filePath, page, pageSize, cts.Token);
    }
}
```